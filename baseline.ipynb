{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JXHQGkHF-60Q",
        "bslzTTLz_FAP",
        "Rv71Gx_7_mD1",
        "w_G0kKsBAOx7",
        "c4WRAGewPATx",
        "GBSp7TO1PKyI",
        "qsUEaWJmqiDS",
        "Ol3i0xX3cSt1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXHQGkHF-60Q"
      },
      "source": [
        "# Import Libraries (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfKWvoZkAo_6"
      },
      "source": [
        "Import our essential Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG7rSodLIfxn"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bslzTTLz_FAP"
      },
      "source": [
        "# Fetch Dataset (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GeonvJs6c_S"
      },
      "source": [
        "Some shell script to check if the data already exists, if not clone it from git.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Spt-nH09kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36073746-bb94-4eed-8a5c-a9160db08ac7"
      },
      "source": [
        "%%shell\n",
        "\n",
        "if [ ! -d '/tmp/pneumoniaDataset' ]; then \n",
        "  mkdir '/tmp/pneumoniaDataset'\n",
        "fi\n",
        "\n",
        "if [ ! -d '/tmp/pneumoniaDataset/.git' ]; then \n",
        "  git clone \"https://github.com/Amzo/xray_images\" '/tmp/pneumoniaDataset/'\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/pneumoniaDataset'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 5838 (delta 0), reused 3 (delta 0), pack-reused 5835\u001b[K\n",
            "Receiving objects: 100% (5838/5838), 1.13 GiB | 37.53 MiB/s, done.\n",
            "Checking out files: 100% (5857/5857), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv71Gx_7_mD1"
      },
      "source": [
        "#Data Setup (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBBFNcZTIhNH"
      },
      "source": [
        "Load our data and generate additional augmented data due to the nature of the small data set. Since the data is already structured into train, test and validate folders, we don't need to split the data here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVNUu9ZmIs_n"
      },
      "source": [
        "def getData(trainDir, testDir, valDir):\n",
        "        class_names = os.listdir(trainDir)\n",
        "        class_types = len(os.listdir(trainDir))\n",
        "\n",
        "        print('Number of classes for Classification: ',class_types)\n",
        "        print(f'The class names are {class_names[0]} and {class_names[1]}')\n",
        "        print('--> Count of Train Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(trainDir + \"/\" +i))))\n",
        "        print('--> Count of Test Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(testDir + '/' +i))))\n",
        "\n",
        "        print('--> Count of Validation Images <---')\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(valDir + '/' +i))))\n",
        "\n",
        "        train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
        "                rotation_range=6,\n",
        "                zoom_range=0.1,\n",
        "                horizontal_flip = True,\n",
        "                vertical_flip = True)\n",
        "\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "        xTrainGen = train_datagen.flow_from_directory(\n",
        "                trainDir,\n",
        "                target_size=(224,224),\n",
        "                shuffle=True,\n",
        "                batch_size=24,\n",
        "                class_mode='binary'\n",
        "        )\n",
        "\n",
        "        xTestGen = test_datagen.flow_from_directory(\n",
        "                testDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=16,\n",
        "                shuffle=True,\n",
        "                class_mode='binary'\n",
        "        )\n",
        "\n",
        "        xValGen = train_datagen.flow_from_directory(\n",
        "                valDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=32,\n",
        "                class_mode='binary'\n",
        "        )\n",
        "\n",
        "        return xTrainGen, xTestGen, xValGen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf-5M4NnOrSp"
      },
      "source": [
        "Setup the data, the physical_device setup is from running on my own machine to setup GPU training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVccqMPJuE5"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "\n",
        "\n",
        "inputTrain = '/tmp/pneumoniaDataset/train'\n",
        "inputTest = '/tmp/pneumoniaDataset/test'\n",
        "inputValidate = '/tmp/pneumoniaDataset/val'\n",
        "imageSize = (224,224,3)\n",
        "\n",
        "xTrain, xTest, xVal = getData(inputTrain, inputTest, inputValidate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Pbu0PyC2C9"
      },
      "source": [
        "# Data Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmGcK260C6Pk"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjqcLo0aHU0m"
      },
      "source": [
        "augmentedImages = [xTrain[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ7W84wxHfe-"
      },
      "source": [
        "plotImages(augmentedImages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_G0kKsBAOx7"
      },
      "source": [
        "# Model Setup (Required for Training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyrRElIuON3t"
      },
      "source": [
        "Very basic cnn, for setting baseline to test against improvements and other models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAxXDWXii2e-"
      },
      "source": [
        "def myModel():\n",
        "  print(\"Defaulting to basic CNN\")\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(224,224,3)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddgr2QD0Olug"
      },
      "source": [
        "Return history and the trained model for saving and graphical display"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaCaLFPwWeC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285c5d74-6f8b-4bd9-ef46-636363c73353"
      },
      "source": [
        "myCNN = myModel()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defaulting to basic CNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR4kS6u70LoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c731811-3ec8-41d1-d42e-43fa00667fa8"
      },
      "source": [
        "myCNN.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 222, 222, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 220, 220, 32)      4640      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 218, 218, 16)      4624      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 760384)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 760385    \n",
            "=================================================================\n",
            "Total params: 770,097\n",
            "Trainable params: 770,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4WRAGewPATx"
      },
      "source": [
        "# Train Model (Optional) - Can Load trained model further down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DkFgq_jJZoo"
      },
      "source": [
        "def modelTrain(model, xTrain, xVal, batchSize):\n",
        "  history = model.fit(xTrain,\n",
        "    epochs=10,\n",
        "    validation_data=xVal,\n",
        "    verbose=1,\n",
        "    batch_size=batchSize\n",
        "  )\n",
        "\n",
        "  return history, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHJasj-4ASJS"
      },
      "source": [
        "94% train accuracy, 88% validation accuracy and around 85% test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rZf1FgsjtZH"
      },
      "source": [
        "cnnHistory, trainedCNN = modelTrain(myCNN, xTrain, xVal, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehs1xNMaAtHP"
      },
      "source": [
        "Save the model to the mounted drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbhAX86VrCAm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H7hw9ONlDBY"
      },
      "source": [
        "trainedCNN.save('/content/gdrive/MyDrive/baselineCNN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQjL0vsq_81"
      },
      "source": [
        "# Store data (serialize)\n",
        "with open('/content/gdrive/MyDrive/baselineHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(cnnHistory.history, outFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBSp7TO1PKyI"
      },
      "source": [
        "# Load Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6izKg_AkaH9G"
      },
      "source": [
        "Some more shell script to pull the trained model from my one drive. While I can access it if I mount my drive, no one else can. This allows anyone running the notebook to pull the trained model directly from my onedrive with wget.\n",
        "\n",
        "This function was supposed to be reusable, however, each cell spawns a new shell process, so declared functions and variables aren't reusable in other cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaVs3xmHU8Ol"
      },
      "source": [
        "%%shell\n",
        "function getFile() {\n",
        "  googleURL=\"https://docs.google.com/uc?export=download\"\n",
        "  wgetCMD=\"wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate\"\n",
        "  fileID=\"$1\"\n",
        "  outFILE=\"/tmp/$2\"\n",
        "\n",
        "  if [ -f $outFILE ]; then\n",
        "    rm -f $outFILE\n",
        "  fi\n",
        "  \n",
        "  wget --load-cookies /tmp/cookies.txt \"$googleURL&confirm=$($wgetCMD '$googleURL&id=$fileID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$fileID\" -O $outFILE\n",
        "  rm -rf /tmp/cookies.txt\n",
        "  \n",
        "}\n",
        "\n",
        "# model file ID\n",
        "getFile \"1y0A74bnzR-2cpkMWEhPVRYPYKQrgobv9\" \"trainedCNN.zip\"\n",
        "\n",
        "outDIR=\"/tmp/trainedModels\"\n",
        "\n",
        "# check if the directory exits, if not create it\n",
        "if [ ! -d $outDIR ]; then \n",
        "  mkdir -p $outDir; \n",
        "fi\n",
        "\n",
        "# extract the model\n",
        "unzip -o -d $outDIR $outFILE \n",
        "\n",
        "#history json file ID\n",
        "getFile \"10k4nIF7SarOreD6T-bWrhqMQ2EhxJ9I9\" \"trainedCNNHistory.pickle\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFZXn_RecC9Y"
      },
      "source": [
        "Load the model train history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOjMUPTiwp7r"
      },
      "source": [
        "with open('/tmp/trainedCNNHistory.pickle', 'rb') as input:\n",
        "    cnnHistory = pickle.load(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un8NbX1ecNkS"
      },
      "source": [
        "Can Finally load the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_8CltE8bXhy"
      },
      "source": [
        "trainedCNN = tf.keras.models.load_model('/tmp/trainedModels/baselineCNN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsUEaWJmqiDS"
      },
      "source": [
        "# Test Model (Requires a trained or Loaded Model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkVU2VqwgLiZ"
      },
      "source": [
        "print(\"Running myCNN model against test set\")\n",
        "ev = trainedCNN.evaluate(xTest)\n",
        "print(\"\\n%s: %.f%%\" % (trainedCNN.metrics_names[1], ev[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol3i0xX3cSt1"
      },
      "source": [
        "# Model Visualisation (Requires a trained or loaded model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiZF8Bsl5CMI"
      },
      "source": [
        "Since we can't pickle weakref objects, we pickle the actual history. If the model has been trained, then cnnHistory.history will contain the results, otherwise if we have loaded the pickle file, just cnnHistory will contain the results. To get around this use try, except."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83txYOQHAwDW"
      },
      "source": [
        "try:\n",
        "  plt.plot(cnnHistory.history['accuracy'], label='accuracy')\n",
        "  plt.plot(cnnHistory.history['val_accuracy'], label = 'val_accuracy')\n",
        "except AttributeError:\n",
        "  plt.plot(cnnHistory['accuracy'], label='accuracy')\n",
        "  plt.plot(cnnHistory['val_accuracy'], label = 'val_accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = trainedCNN.evaluate(xTest, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQgmuJkVNT92"
      },
      "source": [
        "# summarize history for loss\n",
        "try:\n",
        "  plt.plot(cnnHistory.history['loss'])\n",
        "  plt.plot(cnnHistory.history['val_loss'])\n",
        "except AttributeError:\n",
        "  plt.plot(cnnHistory['loss'])\n",
        "  plt.plot(cnnHistory['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}