{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnModels.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dTafmHjGPelh",
        "wPXRjxElvAUN",
        "yst13qUP7EpW",
        "Rj1yHyb6JCYF",
        "SKW_CwJXBVdJ",
        "2VCGKVPnD7oZ",
        "BK7WVyUAGP2q"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amzo/pneumonia/blob/main/cnnModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RNOwytpsTnf"
      },
      "source": [
        "\n",
        "\n",
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxNsL-YjsXCX"
      },
      "source": [
        "Is this notebook there is the option to either train or load 4 additional models ontop of our model that we have created. These models where to compare their accuracy to our models accuracy and to also experiment with ensembling to see how the accuracy improved, which can be tested in the ensembling section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DOLUJWcsxmV"
      },
      "source": [
        "For the sake of speed, the training of the models can be skipped and the pretrained version can be fetched to save a substantial amount of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh3RClj9_Bf3"
      },
      "source": [
        "# Import Libraries (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfKWvoZkAo_6"
      },
      "source": [
        "Import our essential Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG7rSodLIfxn"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications import InceptionV3, DenseNet121\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Input, Average\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "libaryIsImported = True;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWubS2Xl_FsF"
      },
      "source": [
        "# Fetch Dataset (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GeonvJs6c_S"
      },
      "source": [
        "Some shell script to check if the data already exists, if not clone it from git.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Spt-nH09kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7245b56-2925-4481-ea35-f04c3bd6f3bf"
      },
      "source": [
        "%%shell\n",
        "\n",
        "if [ ! -d '/tmp/pneumoniaDataset' ]; then \n",
        "  mkdir '/tmp/pneumoniaDataset'\n",
        "fi\n",
        "\n",
        "if [ ! -d '/tmp/pneumoniaDataset/.git' ]; then \n",
        "  git clone \"https://github.com/Amzo/xray_images\" '/tmp/pneumoniaDataset/'\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqnKkQF7pVJF"
      },
      "source": [
        "dataIsFetched = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edyvCsH3_WwQ"
      },
      "source": [
        "# Datasetup (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBBFNcZTIhNH"
      },
      "source": [
        "Load our data and generate additional augmented data due to the nature of the small data set. Since the data is already structured into train, test and validate folders, we don't need to split the data here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVNUu9ZmIs_n"
      },
      "source": [
        "def getData(trainDir, testDir, valDir):\n",
        "        class_names = os.listdir(trainDir)\n",
        "        class_types = len(os.listdir(trainDir))\n",
        "\n",
        "        print('Number of classes for Classification: ',class_types)\n",
        "        print(f'The class names are {class_names[0]} and {class_names[1]}')\n",
        "        print('--> Count of Train Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(trainDir + \"/\" +i))))\n",
        "        print('--> Count of Test Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(testDir + '/' +i))))\n",
        "\n",
        "        print('--> Count of Validation Images <---')\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(valDir + '/' +i))))\n",
        "\n",
        "        trainDatagen = ImageDataGenerator(rescale=1./255.0,\n",
        "                rotation_range=6,\n",
        "                zoom_range=0.3,\n",
        "                brightness_range= [0.8, 1.3],\n",
        "                horizontal_flip = True,\n",
        "                vertical_flip = True\n",
        "                )\n",
        "\n",
        "        testDatagen = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "        xTrainGen = trainDatagen.flow_from_directory(\n",
        "                trainDir,\n",
        "                target_size=(224,224),\n",
        "                shuffle=True,\n",
        "                batch_size=24,\n",
        "                class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        xTestGen = testDatagen.flow_from_directory(\n",
        "                testDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=16,\n",
        "                shuffle=True,\n",
        "                class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        xValGen = trainDatagen.flow_from_directory(\n",
        "                valDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=32,\n",
        "                class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        return xTrainGen, xTestGen, xValGen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVccqMPJuE5"
      },
      "source": [
        "try:\n",
        "  dataIsFetched\n",
        "except NameError:\n",
        "  print(\"Data has not been fetched, run the fetch data cells\")\n",
        "else:\n",
        "  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "  assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "\n",
        "\n",
        "  inputTrain = '/tmp/pneumoniaDataset/train'\n",
        "  inputTest = '/tmp/pneumoniaDataset/test'\n",
        "  inputValidate = '/tmp/pneumoniaDataset/val'\n",
        "\n",
        "  imageSize = (224,224,3)\n",
        "\n",
        "\n",
        "  xTrain, xTest, xVal = getData(inputTrain, inputTest, inputValidate)\n",
        "\n",
        "  dataIsSetup = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhCmy4Xj_mgB"
      },
      "source": [
        "# Data Visualisation (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IytTvLg7_qAp"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FiQHMJa_ubx"
      },
      "source": [
        "try:\n",
        "  dataIsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the dataSetup section before training\")\n",
        "else:\n",
        "  augmentedImages = [xTrain[0][0][0] for i in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G79arOf5_vLy"
      },
      "source": [
        "plotImages(augmentedImages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw27h6HZAbDE"
      },
      "source": [
        "# Model Setup (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAxXDWXii2e-"
      },
      "source": [
        "def myModel():\n",
        "  print(\"Defaulting to basic CNN\")\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(224,224,3)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB4tKR7-IzTY"
      },
      "source": [
        "def modelBuild(inputShape, modelType):\n",
        "  model = Sequential()\n",
        "  if (modelType == \"xception\"):\n",
        "    print(\"Setting up xception model\")\n",
        "    xception = Xception(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(xception)\n",
        "\n",
        "  elif (modelType == \"resnet\"):\n",
        "    print(\"Setting up resnet50 model\")\n",
        "    resnet = ResNet50V2(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(resnet)\n",
        "\n",
        "  elif (modelType == \"vgg19\"):\n",
        "    print(\"Setting up vgg19 model\")\n",
        "    vgg = VGG19(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(vgg)\n",
        "  elif (modelType == \"inception\"):\n",
        "    print(\"Setting up inception model\")\n",
        "    inception = InceptionV3(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(inception)\n",
        "  elif (modelType == \"densenet\"):\n",
        "    print(\"Setting up densenet model\")\n",
        "    densenet = DenseNet121(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(densenet)\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(Dense(2,activation=\"softmax\"))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaCaLFPwWeC4"
      },
      "source": [
        "try:\n",
        "  libaryIsImported, dataIsSetup\n",
        "except NameError:\n",
        "  print(\"Libary has not been imported, or Data has not been setup, please run the libary and Data setup cells.\")\n",
        "else:\n",
        "  xception = modelBuild(imageSize, 'xception')\n",
        "  vgg19 = modelBuild(imageSize, 'vgg19')\n",
        "  resnet = modelBuild(imageSize, 'resnet')\n",
        "  inception = modelBuild(imageSize, 'inception')\n",
        "  densenet = modelBuild(imageSize, 'densenet')\n",
        "  myCNN = myModel()\n",
        "\n",
        "  modelsSetup = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Ch1zUlI90P"
      },
      "source": [
        "# Train Models (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcLxC6OXI6gI"
      },
      "source": [
        "checkoutPath = '/tmp/Best'\n",
        "\n",
        "modelCheckpointCallback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkoutPath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DkFgq_jJZoo"
      },
      "source": [
        "def modelTrain(model, xTrain, xVal, batchSize):\n",
        "  history = model.fit(xTrain,\n",
        "    epochs=10,\n",
        "    validation_data=xVal,\n",
        "    verbose=1,\n",
        "    batch_size=batchSize,\n",
        "    callbacks=[modelCheckpointCallback]\n",
        "  )\n",
        "\n",
        "  return history, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJScHMVXNNsQ"
      },
      "source": [
        "I could create a function to check if the models have been setup, but you can never be certain if a cell has been executed or not, so rely on global variables being true or false. This means duplication, but it's should reduce errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojGIIzgYzOa8"
      },
      "source": [
        "Train the Inception Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShyxwhvuFfIr"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  inceptionHistoy, trainedInception = modelTrain(inception, xTrain, xVal, 32)\n",
        "  trainedInception = tf.keras.models.load_model(checkoutPath)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drYkBM-0zRCx"
      },
      "source": [
        "Train the VGG model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVv-d5DQW66n"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  vggHistory, trainedVGG = modelTrain(vgg19, xTrain, xVal, 32)\n",
        "  trainedVGG = tf.keras.models.load_model(checkoutPath)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqc2GOP5zTib"
      },
      "source": [
        "Train the resnet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNKvW-xEdfze"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  resnetHistory, trainedResnet = modelTrain(resnet, xTrain, xVal, 32)\n",
        "  trainedResnet = tf.keras.models.load_model(checkoutPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH6le3wBzWaE"
      },
      "source": [
        "Train our CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rZf1FgsjtZH"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  ourCNNHistory, trainedCNN = modelTrain(myCNN, xTrain, xVal, 32)\n",
        "  trainedCNN = tf.keras.models.load_model(checkoutPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GnGzfB-DZEn"
      },
      "source": [
        "Train the xception model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qH-s05GW6Q"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  xceptionHistory, trainedXception = modelTrain(xception, xTrain, xVal, 32)\n",
        "  trainedXception = tf.keras.models.load_model(checkoutPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJrDgbAiDbPs"
      },
      "source": [
        "Train the densenet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O4MVWQADIb6"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  densenetHistory, trainedDensenet = modelTrain(densenet, xTrain, xVal, 32)\n",
        "  trainedDensenet = tf.keras.models.load_model(checkoutPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTafmHjGPelh"
      },
      "source": [
        "# Save Trained Models (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJ0NoZgQEWO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H7hw9ONlDBY"
      },
      "source": [
        "try:\n",
        "  inceptionHistory.History\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the Inception model to save?\")\n",
        "else:\n",
        "  trainedInception.save('/content/gdrive/MyDrive/Inception')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/inceptionHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(inceptionHistoy.history, outFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT_ErbE4Pi_h"
      },
      "source": [
        "try:\n",
        "  vggHistory.history\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the VGG model to save?\")\n",
        "else:\n",
        "  trainedVGG.save('/content/gdrive/MyDrive/VGG')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/vggHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(vggHistory.history, outFile)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tK-y-0gPuI6"
      },
      "source": [
        "try:\n",
        "  resnetHistory.History\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the resnet model to save?\")\n",
        "else:\n",
        "  trainedResnet.save('/content/gdrive/MyDrive/Resnet')\n",
        "  \n",
        "  with open('/content/gdrive/MyDrive/resnetHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(resnetHistory.history, outFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLchU53DP8Js"
      },
      "source": [
        "try:\n",
        "  ourCNNHistory.history\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained myCNN model to save?\")\n",
        "else:\n",
        "  trainedCNN.save('/content/gdrive/MyDrive/myCNN')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/ourCNNHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(ourCNNHistory.history, outFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfktWugYPRSu"
      },
      "source": [
        "try:\n",
        "  xceptionHistory.history\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the Xception model to save?\")\n",
        "else:\n",
        "  trainedXception.save('/content/gdrive/MyDrive/xception')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/xceptionHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(xceptionHistory.history, outFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0soNbjgP3Sj"
      },
      "source": [
        "try:\n",
        "  densenetHistory.history\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the densenet model to save?\")\n",
        "else:\n",
        "  trainedDensenet.save('/content/gdrive/MyDrive/densenet')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/denseNetHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(densenetHistory.history, outFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPXRjxElvAUN"
      },
      "source": [
        "# Fetch Trained Models (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpr86FHc5yOh"
      },
      "source": [
        "This shell script will fetch all the models and history from my one drive so that it can be loaded. Will save an hour or two over waiting for training to finish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc4--Bgm5nwH"
      },
      "source": [
        "Shell variables don't appear to be reusable from other cells, so perform all the shell script in one cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf8UQEGfvMTN"
      },
      "source": [
        "%%shell\n",
        "function extractModel() {\n",
        "  outDIR=\"/tmp/trainedModels/\"\n",
        "\n",
        "  # check if the directory exits, if not create it\n",
        "  if [ ! -d $outDIR ]; then \n",
        "    mkdir -p $outDIR; \n",
        "  fi\n",
        "\n",
        "  # extract the model\n",
        "  echo \"extracting ${1} to ${outDIR}\"\n",
        "  unzip -q -o -d $outDIR $1 \n",
        "}\n",
        "\n",
        "function getFile() {\n",
        "  googleURL=\"https://docs.google.com/uc?export=download\"\n",
        "  echo \"fetching file: ${2}\"\n",
        "  sleep 3\n",
        "  wgetCMD=\"wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate\"\n",
        "  fileID=\"$1\"\n",
        "  outFILE=\"/tmp/$2\"\n",
        "\n",
        "  if [ -f $outFILE ]; then\n",
        "    rm -f $outFILE\n",
        "  fi\n",
        "  \n",
        "  wget  -q --load-cookies /tmp/cookies.txt \"$googleURL&confirm=$($wgetCMD \"$googleURL&id=$fileID\" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$fileID\" -O $outFILE\n",
        "  rm -rf /tmp/cookies.txt\n",
        "  \n",
        "  if [ ${outFILE##*.} == \"zip\" ]; then\n",
        "    extractModel $outFILE\n",
        "  fi\n",
        "}\n",
        "\n",
        "# inception model\n",
        "getFile \"185GypHJV8sTcL3siYXinoClbXP0OEYr1\" \"trainedInception.zip\"\n",
        "\n",
        "# inception history\n",
        "getFile \"1kqAMFgH5H-_k1cKYuuatSuZiG-xtajh_\" \"inceptionHistory.pickle\"\n",
        "\n",
        "# vgg model\n",
        "getFile \"163-EY3aU6_7OP0Ds2Gq4bIu9r84f4txJ\" \"trainedVgg.zip\"\n",
        "\n",
        "# vgg history\n",
        "getFile \"1-0H4ZjHitt8FMC1ZjZun1wlXrFMjFE5N\" \"vggHistory.pickle\"\n",
        "\n",
        "# resnet model\n",
        "getFile \"1E4pHn5-4-9VXDIdlk9qFZya1TjL_u3P-\" \"trainedResnet.zip\"\n",
        "\n",
        "# resnet history\n",
        "getFile \"1-0nN6H7lMCNPD4tlS_CXD1JMEXPcFnc9\" \"resnetHistory.pickle\"\n",
        "\n",
        "# myCNN model\n",
        "getFile \"1CA9XVWkRQ_JgMQ3y3eNcMgTB3tTdDANm\" \"trainedCNN.zip\"\n",
        "\n",
        "# myCNN history\n",
        "getFile \"1-BFAv4_m3fwlYLgWCWbziSQPplKlGfvQ\" \"ourCNNHistory.pickle\"\n",
        "\n",
        "# xception model\n",
        "getFile \"1qqRKAyN5lowZ3VE8cQZWBU54eP-QA9q-\" \"trainedXception.zip\"\n",
        "\n",
        "# xception history\n",
        "getFile \"1-HHmEafOoAMlYXngAS8sjagA-Evlc3n9\" \"xceptionHistory.pickle\"\n",
        "\n",
        "# denseNet model\n",
        "getFile \"109dzTKUYszKO8SmKIh3f4bPT0nPsoN-5\" \"densenet.zip\"\n",
        "\n",
        "# denseNet history\n",
        "getFile \"1-QorYN-kWmrrrLKUTQlALFoLPCAH0eBK\" \"densenetHistory.pickle\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twWwJ9AY6_SY"
      },
      "source": [
        "modelsAreFetched = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yst13qUP7EpW"
      },
      "source": [
        "# Load Models (Required)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N48GiZSj7HY6"
      },
      "source": [
        "historyList = [\"inceptionHistory\", \"vggHistory\", \"resnetHistory\", \"ourCNNHistory\", \"xceptionHistory\", \"densenetHistory\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5hAZTnh7gHO"
      },
      "source": [
        "modelList = [\"Inception\", \"Resnet\", \"VGG\", \"myCNN\", \"xception\", \"densenet\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COQ3DIEn7rfI"
      },
      "source": [
        "try:\n",
        "  modelsAreFetched\n",
        "except NameError:\n",
        "  print(\"You need to fetch the models to load them\")\n",
        "else:\n",
        "  for pickleFile in historyList:\n",
        "    with open('/tmp/' + pickleFile + '.pickle', 'rb') as input:\n",
        "      if (pickleFile == \"inceptionHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        inceptionHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"resnetHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        resnetHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"vggHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        vggHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"ourCNNHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        myCNNHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"xceptionHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        xceptionHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"densenetHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        xceptionHistory = pickle.load(input)\n",
        "\n",
        "      historyIsFetched = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ0JdTHy8_q0"
      },
      "source": [
        "try:\n",
        "  modelsAreFetched\n",
        "except NameError:\n",
        "  print(\"You have to fetch the models before you can load them\")\n",
        "else:\n",
        "  for trainedModel in modelList:\n",
        "    print(\"Loading model \" + trainedModel)\n",
        "    if (trainedModel == \"Inception\"):\n",
        "      trainedInception = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"Resnet\"):\n",
        "      trainedResnet = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"VGG\"):\n",
        "      trainedVGG = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"myCNN\"):\n",
        "      trainedCNN = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"xception\"):\n",
        "      trainedXception = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"densenet\"):\n",
        "      trainedDensenet = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj1yHyb6JCYF"
      },
      "source": [
        "# Test Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmy7LbYNnY2q"
      },
      "source": [
        "def evaluateModel(model, testSet):\n",
        "  ev = model.evaluate(testSet)\n",
        "  print(\"\\n%s: %.f%%\" % (model.metrics_names[1], ev[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkVU2VqwgLiZ"
      },
      "source": [
        "try:\n",
        "  dataIsSetup\n",
        "except NameError:\n",
        "  print(\"Please run datasetup cells first\")\n",
        "else:\n",
        "  for trainedModel in modelList:\n",
        "      print(\"Running \" + trainedModel + \" against test set\")\n",
        "      if (trainedModel == \"Inception\"):\n",
        "        evaluateModel(trainedInception, xTest)\n",
        "      elif (trainedModel == \"Resnet\"):\n",
        "        evaluateModel(trainedResnet, xTest)\n",
        "      elif (trainedModel == \"VGG\"):\n",
        "        evaluateModel(trainedVGG, xTest)\n",
        "      elif (trainedModel == \"myCNN\"):\n",
        "        pred = evaluateModel(trainedCNN, xTest)\n",
        "      elif (trainedModel == \"xception\"):\n",
        "        evaluateModel(trainedXception, xTest)\n",
        "      elif (trainedModel == \"densenet\"):\n",
        "        evaluateModel(trainedDensenet, xTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKW_CwJXBVdJ"
      },
      "source": [
        "# Model History Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83txYOQHAwDW"
      },
      "source": [
        "def visualiseHistory(historyFile):\n",
        "  try:\n",
        "    plt.plot(historyFile.history['accuracy'], label='accuracy')\n",
        "    plt.plot(historyFile.history['val_accuracy'], label = 'val_accuracy')\n",
        "  except AttributeError:\n",
        "    plt.plot(historyFile['accuracy'], label='accuracy')\n",
        "    plt.plot(historyFile['val_accuracy'], label = 'val_accuracy')\n",
        "\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([0.5, 1])\n",
        "  plt.legend(loc='lower right')\n",
        "\n",
        "  test_loss, test_acc = trainedCNN.evaluate(xTest, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNgIMgwbBW6m"
      },
      "source": [
        "def visualiseLoss(historyFile):\n",
        "  # summarize history for loss\n",
        "  try:\n",
        "    plt.plot(historyFile.history['loss'])\n",
        "    plt.plot(historyFile.history['val_loss'])\n",
        "  except AttributeError:\n",
        "    plt.plot(historyFile['loss'])\n",
        "    plt.plot(historyFile['val_loss'])\n",
        "\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_AWDLmoBs3P"
      },
      "source": [
        "visualiseHistory(inceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0nkXs4qB-YC"
      },
      "source": [
        "visualiseLoss(inceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiQhlP4eCP7t"
      },
      "source": [
        "visualiseHistory(vggHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZDWwiuDCsAS"
      },
      "source": [
        "visualiseLoss(vggHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woPIVez7CvCB"
      },
      "source": [
        "visualiseHistory(myCNNHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UdY38jECzdy"
      },
      "source": [
        "visualiseLoss(myCNNHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b2VRnQYC2LS"
      },
      "source": [
        "visualiseHistory(resnetHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbpZcs1aC4Py"
      },
      "source": [
        "visualiseLoss(resnetHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9APZSemC-Fw"
      },
      "source": [
        "visualiseHistory(xceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Jv8dSFDAlH"
      },
      "source": [
        "visualiseLoss(xceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VCGKVPnD7oZ"
      },
      "source": [
        "# Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-kPAA2yE21t"
      },
      "source": [
        "def getVoting():\n",
        "  models = list()\n",
        "  models.append(trainedInception)\n",
        "  models.append(trainedVGG)\n",
        "  models.append(trainedResnet)\n",
        "  models.append(trainedCNN)\n",
        "  models.append(trainedXception)\n",
        "  models.append(trainedDensenet)\n",
        "\n",
        "  return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daY_7ikxFGDw"
      },
      "source": [
        "combinedModel = getVoting()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MdpWb4azOfa"
      },
      "source": [
        "modelInput = Input(shape=(224, 224, 3))\n",
        "modelOutputs = [model(modelInput) for model in combinedModel]\n",
        "ensembleOutput = Average()(modelOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-1kmCqiFVJB"
      },
      "source": [
        "ensembleModel = Model(inputs=modelInput, outputs=ensembleOutput, name='ensemble')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Px2C7e6rr0"
      },
      "source": [
        "ensembleModel.compile(optimizer='adam',\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXRgv5_K7dnk"
      },
      "source": [
        "print(\"Running ensembled model against test set\")\n",
        "evaluateModel(ensembleModel, xTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK7WVyUAGP2q"
      },
      "source": [
        "# Optional Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsmp3kn9JpId"
      },
      "source": [
        "Shell script can't be reused, so redeclare getFile() here, I could either fetch the optional data with the model, or redo the function in python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35I8e7G2JhdU"
      },
      "source": [
        "%%shell\n",
        "function getFile() {\n",
        "  googleURL=\"https://docs.google.com/uc?export=download\"\n",
        "  echo \"fetching file: ${2}\"\n",
        "  wgetCMD=\"wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate\"\n",
        "  fileID=\"$1\"\n",
        "  outFILE=\"/tmp/$2\"\n",
        "\n",
        "  if [ -f $outFILE ]; then\n",
        "    rm -f $outFILE\n",
        "  fi\n",
        "  \n",
        "  wget  -q --load-cookies /tmp/cookies.txt \"$googleURL&confirm=$($wgetCMD \"$googleURL&id=$fileID\" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$fileID\" -O $outFILE\n",
        "  rm -rf /tmp/cookies.txt\n",
        "}\n",
        "\n",
        "getFile \"1OMzk9acsG07iKkEn6P71evY1kvmScwFD\" \"optionalData.zip\"\n",
        "\n",
        "outDIR=\"/tmp/optionalData/\"\n",
        "if [ ! -d $outDIR ]; then \n",
        "  mkdir -p $outDIR; \n",
        "fi\n",
        "unzip -q -o -d $outDIR \"/tmp/optionalData.zip\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IokUkjfN89g"
      },
      "source": [
        "This is my sanity check to ensure that all the optional data has never been seen before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9afWTvGsK5ZR"
      },
      "source": [
        "%%shell\n",
        "\n",
        "hashFile=\"/tmp/hashes.txt\"\n",
        "optionalDataDir=\"/tmp/optionalData\"\n",
        "originalDataDir=\"/tmp/pneumoniaDataset\"\n",
        "\n",
        "if [ -f \"${hashFile}\" ]; then\n",
        "  rm \"${hashFile}\"\n",
        "fi\n",
        "\n",
        "if [ -d \"${optionalDataDir}\" ] || [ -d \"${originalDataDir}\" ]; then\n",
        "  echo \"Caching all file hashes\"\n",
        "  for x in $(ls ${originalDataDir}/*/*/* ); do\n",
        "      newMD5=$(md5sum ${x} | awk -F ' ' '{print $1}')\n",
        "      echo \"${newMD5}:${x}\" >> ${hashFile}\n",
        "  done\n",
        "  echo \"Caching done\"\n",
        "\n",
        "  echo \"Checking optional data against cached hashes\"\n",
        "  for i in $(ls ${optionalDataDir}/*/*); do\n",
        "    savedMD5=$(md5sum ${i} | awk -F ' ' '{print $1}')\n",
        "    if $(grep $savedMD5 /tmp/hashes.txt); then\n",
        "      fileName=$(grep $savedMD5 ${hashFile} | awf -F ':' '{print $2}')\n",
        "      echo \"Duplicate files ${i} and ${fileName}\"\n",
        "    fi\n",
        "  done\n",
        "  echo \"Check Complete\"\n",
        "else\n",
        "  echo \"Has the optional data and normal data been fetched?\"\n",
        "fi\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovIg6DVxGWLm"
      },
      "source": [
        "testData = '/tmp/optionalData'\n",
        "class_names = os.listdir(testData)\n",
        "class_types = len(os.listdir(testData))\n",
        "\n",
        "print('Number of classes for Classification: ',class_types)\n",
        "print(f'The class names are {class_names[0]} and {class_names[1]}')\n",
        "print('--> Count of Train Images <--')\n",
        "\n",
        "for i in class_names:\n",
        "  print(i + ':' + str(len(os.listdir(testData + '/' +i))))\n",
        "\n",
        "testDatagen = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "optionalTest = testDatagen.flow_from_directory(\n",
        "  testData,\n",
        "  target_size=(224,224),\n",
        "  batch_size=16,\n",
        "  shuffle=True,\n",
        "  class_mode='categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6OVRx-XTPZh"
      },
      "source": [
        "try:\n",
        "  dataIsSetup\n",
        "except NameError:\n",
        "  print(\"Please run datasetup cells first\")\n",
        "else:\n",
        "  for trainedModel in modelList:\n",
        "      print(\"Running \" + trainedModel + \" against test set\")\n",
        "      if (trainedModel == \"Inception\"):\n",
        "        evaluateModel(trainedInception, optionalTest)\n",
        "      elif (trainedModel == \"Resnet\"):\n",
        "        evaluateModel(trainedResnet, optionalTest)\n",
        "      elif (trainedModel == \"VGG\"):\n",
        "        evaluateModel(trainedVGG, optionalTest)\n",
        "      elif (trainedModel == \"myCNN\"):\n",
        "        pred = evaluateModel(trainedCNN, optionalTest)\n",
        "      elif (trainedModel == \"xception\"):\n",
        "        evaluateModel(trainedXception, optionalTest)\n",
        "      elif (trainedModel == \"densenet\"):\n",
        "        evaluateModel(trainedDensenet, optionalTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8VjPyo44KRM"
      },
      "source": [
        "try:\n",
        "  dataIsSetup, ensembleModel\n",
        "except NameError:\n",
        "  print(\"esembled model or data is not setup\")\n",
        "else:\n",
        "  evaluateModel(ensembleModel, optionalTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNUhxIhowhSm"
      },
      "source": [
        "# Predict Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xg1xDaJgQqx"
      },
      "source": [
        "Function to predict image classification for reuseability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5mIuYfzwrZC"
      },
      "source": [
        "def predictImg(img):\n",
        "  image = cv2.imread(img)\n",
        "  image = cv2.resize(image,(224,224))\n",
        "  image = np.asarray(image)\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "        \n",
        "  for model in combinedModel:\n",
        "    pred = np.argmax(model.predict(image), axis=-1)\n",
        "    print(\"Normal\" if pred == 0 else \"Pneumonia\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zabBhOxAgRTY"
      },
      "source": [
        "Image locations are passed in using the healthy and pneum variables and their classifcation is determined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcLCkF_GfFnr"
      },
      "source": [
        "healthy = '/tmp/pneumoniaDataset/test/NORMAL/IM-0109-0001.jpeg';\n",
        "pneum = '/tmp/pneumoniaDataset/test/PNEUMONIA/person101_bacteria_483.jpeg';\n",
        "\n",
        "print(\"Healthy image classification\")\n",
        "predictImg(healthy)\n",
        "print(\"Pneumonia image classification\")\n",
        "predictImg(pneum)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}